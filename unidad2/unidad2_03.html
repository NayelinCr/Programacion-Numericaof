<!doctype html>
<html lang="es">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>Unidad 2 ¬∑ Actividad 03: Comparaci√≥n OLS vs. Gradiente Descendente</title>

    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&family=Fira+Code&display=swap" rel="stylesheet">

    <style>
        body {
            font-family: 'Poppins', sans-serif;
            margin: 0;
            background: linear-gradient(160deg, #1f1630, #2a2037, #3c2a52);
            color: #f0e6ff;
            display: flex;
            min-height: 100vh;
            overflow-x: hidden;
        }

        /* ===== SIDEBAR ===== */
        .sidebar {
            width: 250px;
            background: rgba(45, 30, 70, 0.95);
            backdrop-filter: blur(8px);
            padding: 2rem 1rem;
            box-shadow: 4px 0 20px rgba(0,0,0,0.5);
            position: fixed;
            top: 0;
            left: 0;
            bottom: 0;
            display: flex;
            flex-direction: column;
            transition: transform 0.3s ease;
        }

        .sidebar h2 {
            font-size: 1.2rem;
            color: #e3ccff;
            text-align: center;
            margin-bottom: 2rem;
            letter-spacing: 0.8px;
            text-shadow: 0 1px 4px rgba(0,0,0,0.4);
        }

        .sidebar a {
            color: #cdb4ff;
            text-decoration: none;
            font-weight: 600;
            padding: 0.6rem 1rem;
            margin: 0.3rem 0;
            border-radius: 8px;
            transition: all 0.3s;
            display: block;
        }

        .sidebar a:hover {
            background: #b388ff;
            color: #2a2037;
            transform: translateX(4px);
        }

        .sidebar a.active {
            background: #b388ff;
            color: #2a2037;
        }

        .toggle-btn {
            position: fixed;
            top: 1rem;
            left: 1rem;
            background: #b388ff;
            color: #2a2037;
            border: none;
            padding: 0.6rem 0.9rem;
            border-radius: 8px;
            font-weight: bold;
            cursor: pointer;
            z-index: 10;
            box-shadow: 0 3px 10px rgba(0,0,0,0.4);
        }

        .sidebar.hide {
            transform: translateX(-100%);
        }

        /* ===== CONTENIDO PRINCIPAL ===== */
        .content {
            flex: 1;
            margin-left: 250px;
            padding: 2rem;
            transition: margin-left 0.3s;
        }

        .content.full {
            margin-left: 0;
        }

        header {
            background: linear-gradient(135deg, #4a2e68, #7e57c2);
            color: white;
            padding: 1.5rem 2rem;
            border-radius: 12px;
            box-shadow: 0 4px 14px rgba(0,0,0,0.45);
            position: relative;
        }

        .estado {
            position: absolute;
            top: 1.2rem;
            right: 2rem;
            display: flex;
            align-items: center;
            gap: 0.6rem;
            font-weight: 600;
            background: rgba(61, 43, 86, 0.9);
            padding: 0.5rem 1rem;
            border-radius: 50px;
            box-shadow: 0 3px 8px rgba(0,0,0,0.5);
            backdrop-filter: blur(5px);
        }

        .burbuja {
            width: 14px;
            height: 14px;
            border-radius: 50%;
            background: #b388ff;
            box-shadow: 0 0 6px #b388ff;
        }

        main {
            background: rgba(56, 40, 78, 0.95);
            padding: 2.2rem;
            margin-top: 2rem;
            border-radius: 18px;
            box-shadow: 0 6px 20px rgba(0,0,0,0.6);
            backdrop-filter: blur(3px);
            transition: transform 0.2s ease;
        }

        main:hover {
            transform: scale(1.01);
        }

        h1 {
            margin: 0.4rem 0 0;
            font-size: 1.9rem;
            text-shadow: 0 2px 6px rgba(0,0,0,0.4);
        }

        h2 {
            color: #d7baff;
            border-bottom: 2px solid #b388ff;
            display: inline-block;
            padding-bottom: 0.4rem;
            margin-bottom: 1rem;
            text-shadow: 0 1px 4px rgba(0,0,0,0.3);
        }

        h3 {
            color: #cdb4ff;
            font-size: 1.2rem;
            margin-top: 1.5rem;
            margin-bottom: 0.8rem;
        }

        h4 {
            color: #cdb4ff;
            font-size: 1.1rem;
            margin-top: 1.5rem;
            margin-bottom: 0.5rem;
        }

        section {
            margin-bottom: 2rem;
        }

        pre {
            background: #2f2043;
            border-radius: 12px;
            padding: 1rem;
            overflow-x: auto;
            font-family: 'Fira Code', monospace;
            color: #e9ddff;
            border: 1px solid #4e3872;
            box-shadow: inset 0 0 6px rgba(255,255,255,0.05);
            line-height: 1.3;
        }

        a {
            color: #d6b6ff;
            text-decoration: none;
            font-weight: 500;
            transition: color 0.2s ease;
        }

        a:hover {
            color: #f1e0ff;
            text-decoration: underline;
        }

        footer {
            text-align: center;
            margin-top: 2rem;
            padding: 1rem 0;
            background: #3a2951;
            color: #e5d0ff;
            font-size: 0.9rem;
            border-top: 1px solid #4e3872;
            box-shadow: 0 -2px 10px rgba(0,0,0,0.4);
            border-radius: 10px;
        }
        
        /* Estilos para ecuaciones y captions */
        .equation {
            text-align: center;
            margin: 1.5rem 0;
            font-size: 1.15rem;
        }
        .figure-caption {
            font-style: italic;
            font-size: 0.9rem;
            text-align: center;
            margin-top: 0.5rem;
            color: #cdb4ff;
        }
        img {
            max-width: 100%;
            height: auto;
            border-radius: 8px;
            margin: 1rem 0;
            display: block;
            box-shadow: 0 4px 10px rgba(0,0,0,0.5);
        }
        
        .content-header {
            margin-top: 1rem;
        }

    </style>
    
    <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']]
      },
      options: {
        skipHtmlTags: ['script','noscript','style','textarea','pre','code']
      }
    };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>

<body>
    <button class="toggle-btn" onclick="toggleSidebar()">‚ò∞</button>

    <aside class="sidebar" id="sidebar">
        <h2>Unidad 1</h2>
        <a href="unidad2_01.html">Actividad 01</a>
        <a href="unidad2_02.html">Actividad 02</a>
        <a href="unidad2_03.html" class="active">Actividad 03</a>
        <a href="unidad2_04.html">Actividad 04</a>
        <a href="unidad2_05.html">Actividad 05</a>
        <a href="unidad2_06.html">Actividad 06</a>
        <a href="../index.html">üè† Volver al inicio</a>
        <a href="../unidad1/unidad1.html">‚û° Ir a Unidad 1</a>
    </aside>

    <div class="content" id="content">
        <header>
            <h1>Actividad 03 ¬∑ Comparaci√≥n OLS vs. Gradiente Descendente</h1>
            <p>16/10/2025</p>
            <div class="estado">
                <div class="burbuja"></div>
                <span>Completada</span>
            </div>
        </header>

        <main>
            <section>
                <h2>Descripci√≥n de la Actividad</h2>
                <p>Programa en Python que permite graficar funciones lineales y restricciones dentro de un plano cartesiano textual. (Nota: El contenido del informe adjunto se centra en la comparaci√≥n OLS vs. Gradiente Descendente para Regresi√≥n Lineal).</p>
            </section>

            <section>
                <h2>Informe de la Actividad</h2>
                <ul>
                    <li>üìÑ <a href="#">Informe (PDF)</a></li>
                </ul>
            </section>

            <section>
                <h2>Desarrollo de la Actividad</h2>
                
                <h2>1. Resumen</h2>
                [cite_start]<p>Este informe presenta la **comparaci√≥n computacional y num√©rica** entre dos m√©todos para estimar una regresi√≥n lineal simple: **M√≠nimos Cuadrados Ordinarios (OLS)** y **Gradiente Descendente (GD)**[cite: 24].</p>
                [cite_start]<p>El estudio se realiz√≥ en R usando **datos simulados** (1000 observaciones) con la relaci√≥n verdadera: $\text{peso} = 2.5 \times \text{talla} + \text{error}$[cite: 25]. [cite_start]Se midieron tiempos de ejecuci√≥n y se compararon los coeficientes estimados[cite: 26].</p>
                
                <p>Resultados clave:</p>
                <ul>
                    [cite_start]<li>**OLS (lm):** Intercepto $\approx -1.6789$, Pendiente $\approx 2.6174$, Tiempo $\approx 0.003$ s[cite: 27].</li>
                    [cite_start]<li>**Gradiente Descendente:** Intercepto $\approx -0.0052$, Pendiente $\approx 2.5071$, Tiempo $\approx 0.165$ s (5000 iteraciones, $\alpha=0.001$)[cite: 28].</li>
                </ul>
                [cite_start]<p>Conclusi√≥n breve: para este problema (1000 observaciones, 1 variable), **OLS es mucho m√°s r√°pido** y entrega la soluci√≥n anal√≠tica exacta[cite: 29]. [cite_start]**GD** requiere iteraciones y es m√°s lento, aunque converge a una soluci√≥n cercana[cite: 30]. [cite_start]Sin embargo, **GD escala mejor** en ciertos escenarios grandes o modelos sin soluci√≥n anal√≠tica[cite: 31].</p>
            </section>

            <hr>

            <section>
                <div class="content-header">
                    <p>Universidad Nacional del Altiplano de Puno</p>
                    <p>¬´A√±o de la recuperaci√≥n y consolidaci√≥n de la econom√≠a peruana¬ª</p>
                </div>
                
                <h2>2. Introducci√≥n</h2>
                [cite_start]<p>En la asignatura de Programaci√≥n Num√©rica se estudian t√©cnicas para resolver problemas matem√°ticos de forma eficiente en computador[cite: 36]. [cite_start]Este trabajo tiene como prop√≥sito comparar dos aproximaciones para estimar una regresi√≥n lineal simple: el **m√©todo cerrado de M√≠nimos Cuadrados** y un **m√©todo iterativo basado en gradiente**[cite: 38]. [cite_start]La comparaci√≥n se hace tanto desde el punto de vista num√©rico (coeficientes, error) como computacional (tiempo de ejecuci√≥n)[cite: 39].</p>

                <h2>3. Marco Te√≥rico</h2>
                <h3>3.1. Introducci√≥n al c√°lculo num√©rico</h3>
                [cite_start]<p>El c√°lculo num√©rico estudia algoritmos para aproximar soluciones de problemas matem√°ticos mediante operaciones finitas[cite: 42]. [cite_start]Se preocupa por la estabilidad, precisi√≥n y eficiencia de los m√©todos[cite: 43].</p>

                <h3>3.2. Conceptos fundamentales (error, convergencia)</h3>
                <ul>
                    [cite_start]<li>**Error absoluto y relativo:** medidas de la diferencia entre la soluci√≥n aproximada y la verdadera[cite: 45].</li>
                    [cite_start]<li>**Convergencia:** proceso por el cual un algoritmo iterativo se aproxima a una soluci√≥n [cite: 46][cite_start]; depende del paso, la condici√≥n del problema y la tolerancia[cite: 47].</li>
                    [cite_start]<li>**Estabilidad num√©rica:** c√≥mo se amplifican los errores de redondeo en las operaciones[cite: 48].</li>
                </ul>

                <h3>3.3. M√©todos directos vs iterativos</h3>
                <ul>
                    [cite_start]<li>**M√©todos directos (Ej. OLS con ecuaciones normales):** Producen una soluci√≥n en un n√∫mero finito de pasos y suelen implicar operaciones matriciales completas[cite: 50].</li>
                    [cite_start]<li>**M√©todos iterativos (Ej. Gradiente Descendente):** Generan una sucesi√≥n que converge a la soluci√≥n [cite: 51][cite_start]; son √∫tiles cuando la matriz es muy grande o dispersa[cite: 52].</li>
                </ul>

                <h3>3.4. Gradiente Descendente</h3>
                [cite_start]<p>El Gradiente Descendente minimiza una funci√≥n objetivo (por ejemplo, el error cuadr√°tico medio) actualizando par√°metros en la direcci√≥n opuesta al gradiente[cite: 54].</p>
                <p>Para la regresi√≥n lineal con par√°metros $\beta=(\beta_{0},\beta_{1})$, las actualizaciones son:</p>
                <div class="equation">
                    $$\beta_{0}\leftarrow\beta_{0}-\alpha\frac{\partial J}{\partial\beta_{0}}$$
                    $$\beta_{1}\leftarrow\beta_{1}-\alpha\frac{\partial J}{\partial\beta_{1}}$$
                </div>
                [cite_start]<p>Donde $J$ es el MSE (Error Cuadr√°tico Medio) y $\alpha$ es la tasa de aprendizaje[cite: 59]. [cite_start]La elecci√≥n de $\alpha$ y del n√∫mero de iteraciones es cr√≠tica para la convergencia[cite: 60].</p>
            </section>

            <hr>

            <section>
                <div class="content-header">
                    <p>Universidad Nacional del Altiplano de Puno</p>
                    <p>¬´A√±o de la recuperaci√≥n y consolidaci√≥n de la econom√≠a peruana¬ª</p>
                </div>

                <h3>3.5. M√≠nimos Cuadrados (OLS) y soluci√≥n anal√≠tica</h3>
                [cite_start]<p>Para regresi√≥n lineal simple, OLS (Ordinary Least Squares) obtiene la **soluci√≥n cerrada** resolviendo $(X^{\prime}X)\beta=X^{\prime}Y$[cite: 62], lo que conduce a la f√≥rmula:</p>
                <div class="equation">
                    $$\beta=(X^{\prime}X)^{-1}X^{\prime}Y$$
                </div>
                [cite_start]<p>Este enfoque es exacto (en aritm√©tica real) y muy eficiente para problemas de dimensi√≥n moderada[cite: 64].</p>

                <h2>4. Objetivos</h2>
                <h3>4.1. Objetivo General</h3>
                [cite_start]<p>Comparar, desde la perspectiva de Programaci√≥n Num√©rica, el rendimiento computacional y la precisi√≥n de OLS frente a Gradiente Descendente al estimar una regresi√≥n lineal simple[cite: 67].</p>

                <h3>4.2. Objetivos Espec√≠ficos</h3>
                <ul>
                    [cite_start]<li>Implementar ambos m√©todos en R usando datos simulados[cite: 69].</li>
                    [cite_start]<li>Medir tiempos de ejecuci√≥n usando `system.time()` y `profvis()`[cite: 70].</li>
                    [cite_start]<li>Comparar coeficientes estimados y errores (MSE)[cite: 71].</li>
                    [cite_start]<li>Redactar conclusiones sobre cu√°ndo elegir cada m√©todo[cite: 72].</li>
                </ul>

                <h2>5. Metodolog√≠a</h2>
                <h3>5.1. Tipo de estudio</h3>
                [cite_start]<p>Estudio experimental y comparativo mediante simulaci√≥n num√©rica[cite: 75].</p>

                <h3>5.2. Fuente de datos</h3>
                [cite_start]<p>Datos simulados en R: $talla\sim N(15,1,5)$, $peso=2,5\times talla+N(0,2)$; se usaron **1000 observaciones**[cite: 77].</p>

                <h3>5.3. Poblaci√≥n y variable de estudio</h3>
                [cite_start]<p>Poblaci√≥n simulada representativa de la relaci√≥n entre "talla" (predictora) y "peso" (respuesta)[cite: 79].</p>
            </section>

            <hr>

            <section>
                <div class="content-header">
                    <p>Universidad Nacional del Altiplano de Puno</p>
                    <p>¬´A√±o de la recuperaci√≥n y consolidaci√≥n de la econom√≠a peruana¬ª</p>
                </div>

                <h3>5.4. Implementaci√≥n computacional</h3>
                [cite_start]<p>Se implementaron los algoritmos en R. Para OLS se utiliz√≥ la funci√≥n nativa `lm()`[cite: 83]. [cite_start]Para GD se implement√≥ el bucle iterativo con **5000 iteraciones** y tasa de aprendizaje $\alpha=0.001$[cite: 84].</p>

                <h3>5.5. Procesamiento y m√©tricas de comparaci√≥n</h3>
                <ul>
                    <li>**Tiempos:** `system.time()` para tiempo total; [cite_start]`profvis()` para an√°lisis por l√≠nea (opcional)[cite: 86].</li>
                    [cite_start]<li>**Precisi√≥n:** Coeficientes estimados y MSE final[cite: 87].</li>
                    [cite_start]<li>**Visual:** Gr√°ficos de dispersi√≥n con la recta ajustada[cite: 88].</li>
                </ul>

                <h2>6. Experimentos y Resultados</h2>
                <h3>6.1. Preparaci√≥n de datos</h3>
                [cite_start]<p>Se generaron **1000 observaciones** con `set.seed (123)` para garantizar la reproducibilidad de los resultados[cite: 91]. [cite_start]La relaci√≥n verdadera simulada fue $peso = 2.5 \times talla + error$[cite: 92].</p>

                <h3>6.2. Ejecuci√≥n: M√≠nimos Cuadrados Ordinarios (OLS)</h3>
                [cite_start]<p>Se utiliz√≥ la funci√≥n nativa `lm()` de R para la soluci√≥n anal√≠tica de OLS[cite: 95].</p>
                <div class="code-block">
                    <p><em>Listing 1: C√≥digo de Ejecuci√≥n OLS (Resumen)</em></p>
                    <pre><code>set.seed(123)
talla <- rnorm(1000, 15, 1.5)
peso <- 2.5 * talla + rnorm(1000, 0, 2)
datos <- data.frame(talla, peso)

tiempo_ols <- system.time({
    modelo_ols <- lm(peso ~ talla, data = datos)
})

# Resultados
coef(modelo_ols) # Intercepto: -1.6789
                 # Pendiente: 2.6174
# Tiempo: 0.003 s</code></pre>
                </div>
                [cite_start]<p><strong>Resultados:</strong> Intercepto: $-1.6789$, Pendiente: $2.6174$, Tiempo: $0.003$ s[cite: 27].</p>

                <h3>6.3. Ejecuci√≥n: Gradiente Descendente (GD)</h3>
                [cite_start]<p>Se implement√≥ el algoritmo de GD de forma manual, estableciendo una tasa de aprendizaje $\alpha=0.001$ y 5000 iteraciones[cite: 115].</p>
                <div class="code-block">
                    <p><em>Listing 2: C√≥digo de Ejecuci√≥n Gradiente Descendente (Resumen)</em></p>
                    <pre><code>set.seed(123)
talla <- rnorm(1000, 15, 1.5)
peso <- 2.5 * talla + rnorm(1000, 0, 2)
n <- length(talla)

beta0 <- 0
beta1 <- 0
alpha <- 0.001
iteraciones <- 5000

tiempo_gd <- system.time({
    for(i in 1:iteraciones) {
        y_pred <- beta0 + beta1 * talla
        error <- peso - y_pred

        # Gradientes
        grad_b0 <- (-2/n) * sum(error)
        grad_b1 <- (-2/n) * sum(talla * error)

        # Actualizaci√≥n
        beta0 <- beta0 - alpha * grad_b0
        beta1 <- beta1 - alpha * grad_b1
    }
})

# Resultados
# Intercepto: -0.0052
# Pendiente: 2.5071
# Tiempo: 0.165 s</code></pre>
                </div>
                [cite_start]<p><strong>Resultados:</strong> Intercepto: $-0.0052$, Pendiente: $2.5071$, Tiempo: $0.165$ s[cite: 28].</p>
            </section>

            <hr>

            <section>
                <div class="content-header">
                    <p>Universidad Nacional del Altiplano de Puno</p>
                    <p>¬´A√±o de la recuperaci√≥n y consolidaci√≥n de la econom√≠a peruana¬ª</p>
                </div>

                <h3>6.4. Comparaci√≥n de tiempos y coeficientes</h3>
                <ul>
                    <li>**Tiempos:** $\text{OLS}=0.003$ s; $\text{GD}=0.165$ s. [cite_start]**OLS fue aproximadamente 55 veces m√°s r√°pido** en este experimento de dimensi√≥n moderada[cite: 167].</li>
                    [cite_start]<li>**Coeficientes:** Ambas estimaciones est√°n cercanas al valor verdadero $(\beta_{1}=2.5)$[cite: 168]; [cite_start]OLS result√≥ ligeramente m√°s cercano a la soluci√≥n anal√≠tica exacta en este caso[cite: 169].</li>
                    [cite_start]<li>**MSE final (aprox):** El MSE de GD mostr√≥ un descenso lento pero estable a lo largo de las 5000 iteraciones[cite: 171].</li>
                </ul>

                <h2>7. Resultados Globales y Estimaciones</h2>
                [cite_start]<p>De acuerdo con los experimentos realizados[cite: 173]:</p>
                <ul>
                    [cite_start]<li>El m√©todo **OLS** resuelve el problema de forma **directa y eficiente** cuando el n√∫mero de observaciones y variables es moderado[cite: 174].</li>
                    [cite_start]<li>El **Gradiente Descendente** es √∫til para problemas donde la soluci√≥n anal√≠tica es costosa o inexistente [cite: 175][cite_start]; su tiempo depende fuertemente del n√∫mero de iteraciones y del tama√±o del *dataset*[cite: 176, 179].</li>
                    <li>Se recomienda **OLS para modelos lineales sencillos**; [cite_start]**GD** (o variantes como SGD) para **grandes vol√∫menes de datos o modelos complejos**[cite: 180].</li>
                </ul>
            </section>

            <hr>

            <section>
                <div class="content-header">
                    <p>Universidad Nacional del Altiplano de Puno</p>
                    <p>¬´A√±o de la recuperaci√≥n y consolidaci√≥n de la econom√≠a peruana¬ª</p>
                </div>

                <h2>8. Conclusiones</h2>
                <ul>
                    [cite_start]<li>Para el caso estudiado (1000 observaciones, 1 predictor), **OLS fue m√°s eficiente y preciso**[cite: 182].</li>
                    [cite_start]<li>**Gradiente Descendente** requiere ajuste de hiperpar√°metros ($\alpha$, n√∫mero de iteraciones) y suele ser m√°s lento en problemas peque√±os, pero tiene ventajas en **escalabilidad y en problemas sin soluci√≥n cerrada**[cite: 183].</li>
                    [cite_start]<li>En Programaci√≥n Num√©rica es clave elegir el m√©todo que balancee precisi√≥n, costo computacional y estabilidad num√©rica[cite: 184].</li>
                </ul>

                <h2>9. Bibliograf√≠a</h2>
                <ol>
                    <li>Burden, R. L., & Faires, J. D. (2011). [cite_start]*Numerical Analysis.* Brooks/Cole[cite: 186].</li>
                    <li>Nocedal, J., & Wright, S. (2006). [cite_start]*Numerical Optimization.* Springer[cite: 187].</li>
                    <li>James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). [cite_start]*An Introduction to Statistical Learning.* Springer[cite: 188].</li>
                    <li>R Core Team (2024). R: A language and environment for statistical computing. [cite_start]R Foundation for Statistical Computing, Vienna, Austria[cite: 189].</li>
                </ol>
            </section>

            <hr>

            <section>
                <div class="content-header">
                    <p>Universidad Nacional del Altiplano de Puno</p>
                    <p>¬´A√±o de la recuperaci√≥n y consolidaci√≥n de la econom√≠a peruana¬ª</p>
                </div>

                <h2>10. Anexos</h2>
                <h3>10.1. C√≥digo fuente (R) completo</h3>
                <p>Se incluyen a continuaci√≥n los scripts utilizados. [cite_start]Copiar y ejecutar en RStudio o una consola de R para reproducir los resultados y gr√°ficos presentados[cite: 192, 193].</p>

                <h4>OLS (M√≠nimos Cuadrados Ordinarios)</h4>
                <div class="code-block">
                    <p><em>Listing 3: Script Completo OLS</em></p>
                    <pre><code># OLS - 1000 observaciones
set.seed(123)
talla <- rnorm(1000, 15, 1.5)
peso <- 2.5 * talla + rnorm(1000, 0, 2)
datos <- data.frame(talla, peso)

tiempo_ols <- system.time({
    modelo_ols <- lm(peso ~ talla, data = datos)
})

cat("-- RESULTADOS OLS\n")
cat("Intercepto (Œ≤0):", coef(modelo_ols)[1], "\n")
cat("Pendiente (Œ≤1):", coef(modelo_ols)[2], "\n")
cat("Tiempo total:", tiempo_ols["elapsed"], "segundos\n")
summary(modelo_ols)

plot(datos$talla, datos$peso, pch = 19, col = "steelblue",
      main = "Relaci√≥n entre Peso y Talla (OLS)",
      xlab = "Talla", ylab = "Peso")
abline(modelo_ols, col = "red", lwd = 2)</code></pre>
                </div>
            </section>

            <hr>

            <section>
                <div class="content-header">
                    <p>Universidad Nacional del Altiplano de Puno</p>
                    <p>¬´A√±o de la recuperaci√≥n y consolidaci√≥n de la econom√≠a peruana¬ª</p>
                </div>
                <h3>10.2. Salida de Consola y Gr√°ficos (OLS)</h3>
                <p>Gr√°fico de la regresi√≥n lineal OLS sobre los datos simulados.</p>
                [cite_start]<p class="figure-caption">Figura 1: Captura de pantalla de la salida de la consola para el algoritmo de M√≠nimos Cuadrados[cite: 231].</p>

                <h4>Gradiente Descendente (Gradient Descent)</h4>
                <div class="code-block">
                    <p><em>Listing 4: Script Completo Gradiente Descendente</em></p>
                    <pre><code># Gradient Descent 1000 observaciones
set.seed(123)
talla <- rnorm(1000, 15, 1.5)
peso <- 2.5 * talla + rnorm(1000, 0, 2)
n <- length(talla)

beta0 <- 0
beta1 <- 0
alpha <- 0.001
iteraciones <- 5000

# Funci√≥n de Costo (MSE)
costo <- function(b0, b1, x, y) mean((y - (b0 + b1 * x))^2)

tiempo_gd <- system.time({
    for (i in 1:iteraciones) {
        y_pred <- beta0 + beta1 * talla
        error <- peso - y_pred

        # Gradientes
        grad_b0 <- (-2 / n) * sum(error)
        grad_b1 <- (-2 / n) * sum(talla * error)

        # Actualizaci√≥n
        beta0 <- beta0 - alpha * grad_b0
        beta1 <- beta1 - alpha * grad_b1

        if (i %% 1000 == 0) cat("Iteraci√≥n:", i, " Costo:",
                                costo(beta0, beta1, talla, peso), "\n")
    }
})

cat("-- RESULTADOS GRADIENT DESCENT\n")
cat("Intercepto (Œ≤0):", beta0, "\n")
cat("Pendiente (Œ≤1):", beta1, "\n")
cat("Tiempo total:", tiempo_gd["elapsed"], "segundos\n")

plot(talla, peso, pch = 19, col = "darkgreen",
      main = "Relaci√≥n entre Peso y Talla (Gradient Descent)",
      xlab = "Talla", ylab = "Peso")
abline(a = beta0, b = beta1, col = "yellow", lwd = 2)</code></pre>
                </div>
            </section>
            
            <hr>

            <section>
                <div class="content-header">
                    <p>Universidad Nacional del Altiplano de Puno</p>
                    <p>¬´A√±o de la recuperaci√≥n y consolidaci√≥n de la econom√≠a peruana¬ª</p>
                </div>

                <h3>10.3. Salida de Consola y Gr√°ficos (GD)</h3>
                <p>Gr√°fico de la regresi√≥n lineal estimada por Gradiente Descendente.</p>
                [cite_start]<p class="figure-caption">Figura 2: Captura de pantalla de la salida de la consola para el algoritmo de Gradiente Descendente en R[cite: 306].</p>
            </section>
        </main>

        <footer>
            ¬© 2025 Nayelin ¬∑ Portafolio Programaci√≥n Num√©rica üíú
        </footer>
    </div>

    <script>
        function toggleSidebar() {
            const sidebar = document.getElementById('sidebar');
            const content = document.getElementById('content');
            sidebar.classList.toggle('hide');
            content.classList.toggle('full');
        }
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
<script>
  // Elimina todas las etiquetas [cite_start] y [cite: ...] al cargar la p√°gina
  document.addEventListener("DOMContentLoaded", () => {
    document.body.innerHTML = document.body.innerHTML
      .replace(/\[cite_start\]/g, "")
      .replace(/\[cite:\s*\d+\]/g, "");
  });
</script>

</body>
</html>
